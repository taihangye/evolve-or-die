<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Thoughts on Ethics for Data Science | Evolve or Die</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Thoughts on Ethics for Data Science" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Recently, I am taking a online deep learning course on fast.ai. The lesson 3 of the course is focusing on data ethics. The lecturer, Rachel Thomas, touches a few points that I echo back. Around 1:52:50, there is a short discussion Q: Maybe the best way to incentivize ethical behavior it to tie financial or reputational risk to good behavior. In some ways, similar to how companies are now investing in cybersecurity because they don’t want to be the next Equifax. Can grassroots compaigns help in better ethical behaviors with regards to the use of AI? Rachel Thomas: …I think it’s hard for people to make the case to their boses of why they should be investing in cybersecurity. Particularly because cybersecurity is something that when it’s working well, you don’t notice it. …" />
<meta property="og:description" content="Recently, I am taking a online deep learning course on fast.ai. The lesson 3 of the course is focusing on data ethics. The lecturer, Rachel Thomas, touches a few points that I echo back. Around 1:52:50, there is a short discussion Q: Maybe the best way to incentivize ethical behavior it to tie financial or reputational risk to good behavior. In some ways, similar to how companies are now investing in cybersecurity because they don’t want to be the next Equifax. Can grassroots compaigns help in better ethical behaviors with regards to the use of AI? Rachel Thomas: …I think it’s hard for people to make the case to their boses of why they should be investing in cybersecurity. Particularly because cybersecurity is something that when it’s working well, you don’t notice it. …" />
<link rel="canonical" href="https://taihangye.github.io/evolve-or-die/deeplearning/ethics/2021/06/23/thoughts-on-ethics-for-data-science.html" />
<meta property="og:url" content="https://taihangye.github.io/evolve-or-die/deeplearning/ethics/2021/06/23/thoughts-on-ethics-for-data-science.html" />
<meta property="og:site_name" content="Evolve or Die" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-06-23T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Recently, I am taking a online deep learning course on fast.ai. The lesson 3 of the course is focusing on data ethics. The lecturer, Rachel Thomas, touches a few points that I echo back. Around 1:52:50, there is a short discussion Q: Maybe the best way to incentivize ethical behavior it to tie financial or reputational risk to good behavior. In some ways, similar to how companies are now investing in cybersecurity because they don’t want to be the next Equifax. Can grassroots compaigns help in better ethical behaviors with regards to the use of AI? Rachel Thomas: …I think it’s hard for people to make the case to their boses of why they should be investing in cybersecurity. Particularly because cybersecurity is something that when it’s working well, you don’t notice it. …","url":"https://taihangye.github.io/evolve-or-die/deeplearning/ethics/2021/06/23/thoughts-on-ethics-for-data-science.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://taihangye.github.io/evolve-or-die/deeplearning/ethics/2021/06/23/thoughts-on-ethics-for-data-science.html"},"headline":"Thoughts on Ethics for Data Science","dateModified":"2021-06-23T00:00:00-05:00","datePublished":"2021-06-23T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/evolve-or-die/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://taihangye.github.io/evolve-or-die/feed.xml" title="Evolve or Die" /><link rel="shortcut icon" type="image/x-icon" href="/evolve-or-die/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/evolve-or-die/">Evolve or Die</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/evolve-or-die/about/">About Me</a><a class="page-link" href="/evolve-or-die/search/">Search</a><a class="page-link" href="/evolve-or-die/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Thoughts on Ethics for Data Science</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-06-23T00:00:00-05:00" itemprop="datePublished">
        Jun 23, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/evolve-or-die/categories/#deeplearning">deeplearning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/evolve-or-die/categories/#ethics">ethics</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><p>Recently, I am taking a online deep learning <a href="https://course.fast.ai/">course</a> on fast.ai. The lesson 3 of the course is focusing on data ethics. The lecturer, <a href="https://www.fast.ai/about/#rachel">Rachel Thomas</a>, touches a few points that I echo back.
Around <a href="https://youtu.be/krIVOb23EH8?t=6770">1:52:50</a>, there is a short discussion</p>
<blockquote>
  <p>Q: Maybe the best way to incentivize ethical behavior it to tie financial or reputational risk to good behavior. In some ways, similar to how companies are now investing in cybersecurity because they don’t want to be the next Equifax. Can grassroots compaigns help in better ethical behaviors with regards to the use of AI?
Rachel Thomas: …I think it’s hard for people to make the case to their boses of why they should be investing in cybersecurity. Particularly because cybersecurity is something that when it’s working well, you don’t notice it. …</p>
</blockquote>

<p>Lots of things like cybersecurity that people are lacking of incentives/motivation to make an investment before something really bad happens to themselves. My personal experience is when designing a product (or running a service), many companies are eager to launch their product/service as early as possible with little test, and they call it “test it in production; move fast; quicker iteration beats fine-tuning”. In some cases, it will only lead to acceptable level of bad user experience while in others it could be devastating and turns out completely shutting down the business. Is there a good strategy to invest early before everything is to late? As mentioned above, it’s really hard to make the case unless it’s tied to financial/reputational risk, which is more close to a postmortem analysis after something bad happens. It’s easier to start this effort if the leadership team pocesses such mindset of prioritizing quality, privacy, security traits of their product/service, and building a culture around them.</p>

<p>Another point that hits me is around <a href="https://youtu.be/krIVOb23EH8?t=7552">2:05:52</a>. I found the full version of interview and will quote here.</p>
<blockquote>
  <p>WHAT’S WRONG WITH AI
Julia Angwn: <strong>I strongly believe that in order to solve a problem, you have to diagnose it, and that we’re still in the diagnosis phase of this</strong>. If you think about the turn of the century and industrialization, we had, I don’t know, 30 years of child labor, unlimited work hours, terrible working conditions, and it took a lot of journalist muckraking and advocacy to diagnose the problem and have some understanding of what it was, and then the activism to get laws changed.
I feel like we’re in a second industrialization of data information. I think some call it the second machine age. We’re in the phase of just waking up from the heady excitement and euphoria of having access to technology at our fingertips at all times. That’s really been our last 20 years, that euphoria, and now we’re like, “Whoa, looks like there’re some downsides.” I see my role as trying to make as clear as possible what the downsides are, <strong>and diagnosing them really accurately so that they can be solvable. That’s hard work, and lots more people need to be doing it.</strong> It’s increasingly becoming a field, but I don’t think we’re all the way there.</p>
</blockquote>

<p>Dianosing and understanding the full picture of the problem is not an easy problem. It takes non-trivial time to identify the exact problem and serves as the starting point of crafting potential solution. On the one hand, if we don’t fully understand the problem, it may cost way more time and resource to pivot. On the other hand, we can’t spend endless time on diagnosing a problem, it’s not pratical in reality and we never make any progress to exercise some potential solutions to test our understanding. It’s always a evolving and dynamic process that we put enough time ahead to understand the problem, then design solution and test it, measure the results to create a feedback loop to adjust the initial understanding and design a better solution.</p>


  </div><a class="u-url" href="/evolve-or-die/deeplearning/ethics/2021/06/23/thoughts-on-ethics-for-data-science.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/evolve-or-die/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/evolve-or-die/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/evolve-or-die/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Mainly about technology, management, ideas</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/evolve-or-die/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/evolve-or-die/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
